{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single agent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCXIBg+qbNVHK7z0d1Ta9s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravind-11/IITM_Saastra/blob/main/Single_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uOS5--D04D3"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "class Football:  # The class encapsulating the environment\n",
        "    '''\n",
        "    Actions [0 : Stand, 1 : Up, 2 : Right, 3 : Down, 4 : Left]\n",
        "    These are the representing no.s for the mentioned actions\n",
        "    '''\n",
        "\n",
        "    def __init__(self, length=30, width=30, goalPositions=[29, 15]):\n",
        "        \n",
        "        # The player start at random locations\n",
        "        \n",
        "        self.pA=[np.random.randint(length), np.random.randint(length)] \n",
        "            \n",
        "        \n",
        "        self.h = length   # Length of the Football Pitch    \n",
        "        self.w = width    # Width of the Football Pitch\n",
        "        \n",
        "        self.goalPositions = np.array(goalPositions)   # This means that the middle 4 positions at the right and left are the goals\n",
        "        \n",
        "     \n",
        "        \n",
        "        self.reward = 0                            # Initially the reward is 0\n",
        "        \n",
        "        self.observation=np.random.rand(4,)\n",
        "        self.done = bool(0)                          # This stores whether the game needs to be restart with new position (in the case of a goal)\n",
        "\n",
        "    def reset(self):\n",
        "        self.done = bool(0)\n",
        "        self.reward = 0\n",
        "        \n",
        "        self.pA = np.array([np.random.randint(self.h), np.random.randint(self.h)])\n",
        "        \n",
        "        return np.array((*self.pA,(15-self.pA[0]),(15-self.pA[1]))).astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done == bool(1):\n",
        "          self.reset()\n",
        "        self.move(first, action)                   # We chose the first player at random\n",
        "        if self.done == bool(1):\n",
        "          return self.observation, self.reward, self.done\n",
        "        if not done:\n",
        "            self.current_player_num = (self.current_player_num + 1) % 2   \n",
        "        return self.observation,self.reward, self.done\n",
        "\n",
        "    def move(self, player, action):\n",
        "        opponent = 1 - player\n",
        "        \n",
        "        newPosition = self.pA + self.actionToMove(action)\n",
        "        \n",
        "        if self.ballOwner is player and self.isInGoal(*newPosition) >= 0:\n",
        "            self.done = bool(1)\n",
        "            return 1 - self.isInGoal(*newPosition)\n",
        "        # If it's in the board\n",
        "        elif self.isInBoard(*newPosition):\n",
        "            self.positions[player] = newPosition\n",
        "        if(self.ballOwner!=0):\n",
        "          self.reward=-1\n",
        "        return -1\n",
        "\n",
        "    def actionToMove(self, action):\n",
        "        switcher = {\n",
        "            0: [0, 0],\n",
        "            1: [0, 1],\n",
        "            2: [1, 0],\n",
        "            3: [0, -1],\n",
        "            4: [-1, 0],\n",
        "        }\n",
        "        return switcher.get(action)\n",
        "\n",
        "    def isInGoal(self, x, y):\n",
        "        g1, g2 = self.goalPositions\n",
        "        if (g1 <= y <= g2):\n",
        "            if x == 0:\n",
        "                self.done = bool(1)\n",
        "                self.reward = -20 # if the ball reaches the right goal post, then the rewards shall be -1\n",
        "                return 1 \n",
        "            elif x == (self.w-1):\n",
        "                self.done = bool(1)\n",
        "                self.reward = 20 # if the ball reaches the right goal post, then the rewards shall be 1\n",
        "                return 0\n",
        "        return -1\n",
        "\n",
        "    def isInBoard(self, x, y):\n",
        "        if(x<0 or x>29):\n",
        "          return 0\n",
        "        if(y<0 or y>29):\n",
        "          return 0 \n",
        "        return 1\n",
        "        \n",
        "\n",
        "    #def choosePlayer(self):\n",
        "    #    return np.random.randint(0, 2)\n",
        "    def render(self,mode=\"human\"):\n",
        "        \n",
        "\n",
        "        board = ''\n",
        "        for y in range(self.h)[::-1]:\n",
        "            for x in range(self.w):\n",
        "                if ([x, y] == self.pA).all():\n",
        "                    board += 'A' \n",
        "                elif([x,y]==[8,6]):\n",
        "                  board+='O'\n",
        "                else:\n",
        "                    board += '-'\n",
        "            board += '\\n'\n",
        "\n",
        "        print(board)\n",
        "\n",
        "class modf_football(Football,gym.Env):\n",
        "  def __init__(self, length=30, width=30, goalPositions=[29, 15]):\n",
        "    super().__init__()\n",
        "    self.observation_space=gym.spaces.Box(low=-30, high=30,\n",
        "                                        shape=(4,), dtype=np.float32)\n",
        "    self.reward=0\n",
        "    self.action_space=gym.spaces.Discrete(5)\n",
        "    self.name='Football'\n",
        "    self.current_player_num=0\n",
        "    self.observation=np.random.rand(4,)\n",
        "    self.pA = np.array([np.random.randint(self.h), np.random.randint(self.h)])\n",
        "  #modifying the step and move function to get the updated reward system\n",
        "  def step(self, action):\n",
        "        #print('action',action)\n",
        "        if self.done == bool(1):\n",
        "          self.reset()\n",
        "        \n",
        "        self.move(action)                   # We chose the first player at random\n",
        "        if self.done == bool(1):\n",
        "          return self.observation, self.reward, self.done,{}\n",
        "        if not self.done:\n",
        "            self.current_player_num = 0\n",
        "        return self.observation,self.reward, self.done,{}\n",
        "  \n",
        "  def move(self, action):\n",
        "        \n",
        "        newPosition = self.pA + self.actionToMove(action)\n",
        "        \n",
        "       \n",
        "        if self.isInGoal(*newPosition) >= 0:\n",
        "            self.done = bool(1)\n",
        "            return 1 - self.isInGoal(*newPosition)\n",
        "        # If it's in the board\n",
        "        elif self.isInBoard(*newPosition):\n",
        "            self.reward = -0.1 * ((((abs(newPosition[0]-self.goalPositions[0]))+(abs(newPosition[1]-self.goalPositions[1]))))) +0.01*(abs(newPosition[0]-8)+abs(newPosition[1]-6))\n",
        "            self.pA = newPosition\n",
        "        \n",
        "        self.observation=np.array((*self.pA,(15-self.pA[0]),(15-self.pA[1]))).astype(np.float32)\n",
        "        return -1\n",
        "  def seed():\n",
        "      return 0 \n",
        "  def metadata(x):\n",
        "      return 0 \n",
        "  def legal_actions(self):\n",
        "    return gym.spaces.Discrete(5)\n",
        "  def close(self):\n",
        "    pass"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAVZUc4H0_uK"
      },
      "source": [
        "env=modf_football(Football,gym.Env)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XDWqICr1GhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ed9343-bfad-45a4-978e-1943c3f417fe"
      },
      "source": [
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Shape:\", env.observation_space.shape)\n",
        "# Discrete(2) means that there is two discrete actions\n",
        "print(\"Action space:\", env.action_space)\n",
        "\n",
        "# The reset method is called at the beginning of an episode\n",
        "obs = env.reset()\n",
        "# Sample a random action\n",
        "action = env.action_space.sample()\n",
        "print(\"Sampled action:\", action)\n",
        "obs, reward, done, info = env.step(action)\n",
        "# Note the obs is a numpy array\n",
        "# info is an empty dict for now but can contain any debugging info\n",
        "# reward is a scalar\n",
        "print(obs, reward, done, info)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation space: Box(-8.0, 8.0, (4,), float32)\n",
            "Shape: (4,)\n",
            "Action space: Discrete(5)\n",
            "Sampled action: 3\n",
            "[ 5.  0. -1.  4.] -0.5199999999999999 False {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twZOQXF60_KR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd254cb4-fa15-4574-b40a-7f6335a2521a"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!pip install stable-baselines[mpi]==2.10.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting stable-baselines[mpi]==2.10.0\n",
            "  Downloading stable_baselines-2.10.0-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.0.1)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: mpi4py in /tensorflow-1.15.2/python3.7 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Installing collected packages: stable-baselines\n",
            "  Attempting uninstall: stable-baselines\n",
            "    Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCKuQTfQ1IRF"
      },
      "source": [
        "from stable_baselines.common.env_checker import check_env"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xnffJrv1K03"
      },
      "source": [
        "check_env(env, warn=True)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUcyqRd1K2Q"
      },
      "source": [
        "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
        "from stable_baselines.common.cmd_util import make_vec_env\n",
        "\n",
        "# Instantiate the env\n",
        "#env = GoLeftEnv(grid_size=10)\n",
        "# wrap it\n",
        "env = make_vec_env(lambda: env, n_envs=1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j1rooua2biy",
        "outputId": "5d72fc3f-980a-4132-f5db-7385f38b4f14"
      },
      "source": [
        "\n",
        "# Train the agent\n",
        "model = PPO2('MlpPolicy', env, verbose=1).learn(5000)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "| approxkl           | 0.00016907758 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0233        |\n",
            "| fps                | 390           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 1.6092591     |\n",
            "| policy_loss        | -0.0011901138 |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.72e-05      |\n",
            "| total_timesteps    | 128           |\n",
            "| value_loss         | 798.97656     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00020079882 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0209       |\n",
            "| fps                | 1013          |\n",
            "| n_updates          | 2             |\n",
            "| policy_entropy     | 1.6080043     |\n",
            "| policy_loss        | -0.00105682   |\n",
            "| serial_timesteps   | 256           |\n",
            "| time_elapsed       | 0.329         |\n",
            "| total_timesteps    | 256           |\n",
            "| value_loss         | 869.31836     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00016326422 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00599      |\n",
            "| fps                | 1094          |\n",
            "| n_updates          | 3             |\n",
            "| policy_entropy     | 1.6060405     |\n",
            "| policy_loss        | -0.0011041361 |\n",
            "| serial_timesteps   | 384           |\n",
            "| time_elapsed       | 0.457         |\n",
            "| total_timesteps    | 384           |\n",
            "| value_loss         | 1058.5203     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.000404898   |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.000711     |\n",
            "| fps                | 1096          |\n",
            "| n_updates          | 4             |\n",
            "| policy_entropy     | 1.6035156     |\n",
            "| policy_loss        | -0.0035562464 |\n",
            "| serial_timesteps   | 512           |\n",
            "| time_elapsed       | 0.576         |\n",
            "| total_timesteps    | 512           |\n",
            "| value_loss         | 1549.4603     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00085234805 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00748      |\n",
            "| fps                | 1071          |\n",
            "| n_updates          | 5             |\n",
            "| policy_entropy     | 1.5917271     |\n",
            "| policy_loss        | -0.003247564  |\n",
            "| serial_timesteps   | 640           |\n",
            "| time_elapsed       | 0.695         |\n",
            "| total_timesteps    | 640           |\n",
            "| value_loss         | 551.0127      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00053081266 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0182        |\n",
            "| fps                | 1031          |\n",
            "| n_updates          | 6             |\n",
            "| policy_entropy     | 1.5911019     |\n",
            "| policy_loss        | -0.0032745046 |\n",
            "| serial_timesteps   | 768           |\n",
            "| time_elapsed       | 0.818         |\n",
            "| total_timesteps    | 768           |\n",
            "| value_loss         | 102.74374     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0010451296  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0353        |\n",
            "| fps                | 1057          |\n",
            "| n_updates          | 7             |\n",
            "| policy_entropy     | 1.5763932     |\n",
            "| policy_loss        | -0.0074266847 |\n",
            "| serial_timesteps   | 896           |\n",
            "| time_elapsed       | 0.943         |\n",
            "| total_timesteps    | 896           |\n",
            "| value_loss         | 99.58983      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0006738691  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.123         |\n",
            "| fps                | 1102          |\n",
            "| n_updates          | 8             |\n",
            "| policy_entropy     | 1.5714402     |\n",
            "| policy_loss        | -0.0023252228 |\n",
            "| serial_timesteps   | 1024          |\n",
            "| time_elapsed       | 1.07          |\n",
            "| total_timesteps    | 1024          |\n",
            "| value_loss         | 19.70698      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0003718898   |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | 0.122          |\n",
            "| fps                | 1014           |\n",
            "| n_updates          | 9              |\n",
            "| policy_entropy     | 1.5772732      |\n",
            "| policy_loss        | -0.00073078903 |\n",
            "| serial_timesteps   | 1152           |\n",
            "| time_elapsed       | 1.18           |\n",
            "| total_timesteps    | 1152           |\n",
            "| value_loss         | 5.47784        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0006420359 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | 0.246        |\n",
            "| fps                | 1000         |\n",
            "| n_updates          | 10           |\n",
            "| policy_entropy     | 1.5681627    |\n",
            "| policy_loss        | -0.006263942 |\n",
            "| serial_timesteps   | 1280         |\n",
            "| time_elapsed       | 1.31         |\n",
            "| total_timesteps    | 1280         |\n",
            "| value_loss         | 4.1886306    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00014570614 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.23         |\n",
            "| fps                | 970           |\n",
            "| n_updates          | 11            |\n",
            "| policy_entropy     | 1.5880463     |\n",
            "| policy_loss        | -0.0013572993 |\n",
            "| serial_timesteps   | 1408          |\n",
            "| time_elapsed       | 1.44          |\n",
            "| total_timesteps    | 1408          |\n",
            "| value_loss         | 72.209045     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00026802628 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00406       |\n",
            "| fps                | 987           |\n",
            "| n_updates          | 12            |\n",
            "| policy_entropy     | 1.5981312     |\n",
            "| policy_loss        | -0.0025733279 |\n",
            "| serial_timesteps   | 1536          |\n",
            "| time_elapsed       | 1.58          |\n",
            "| total_timesteps    | 1536          |\n",
            "| value_loss         | 159.63812     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00068214315 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.188        |\n",
            "| fps                | 1102          |\n",
            "| n_updates          | 13            |\n",
            "| policy_entropy     | 1.5489829     |\n",
            "| policy_loss        | -0.004740663  |\n",
            "| serial_timesteps   | 1664          |\n",
            "| time_elapsed       | 1.71          |\n",
            "| total_timesteps    | 1664          |\n",
            "| value_loss         | 20.850914     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0011894967  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0128       |\n",
            "| fps                | 1017          |\n",
            "| n_updates          | 14            |\n",
            "| policy_entropy     | 1.5207832     |\n",
            "| policy_loss        | -0.0036145563 |\n",
            "| serial_timesteps   | 1792          |\n",
            "| time_elapsed       | 1.83          |\n",
            "| total_timesteps    | 1792          |\n",
            "| value_loss         | 22.61501      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00074582704 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0644       |\n",
            "| fps                | 1003          |\n",
            "| n_updates          | 15            |\n",
            "| policy_entropy     | 1.4882956     |\n",
            "| policy_loss        | -0.0014004863 |\n",
            "| serial_timesteps   | 1920          |\n",
            "| time_elapsed       | 1.95          |\n",
            "| total_timesteps    | 1920          |\n",
            "| value_loss         | 6.3467703     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00020715973  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | -0.0796        |\n",
            "| fps                | 1110           |\n",
            "| n_updates          | 16             |\n",
            "| policy_entropy     | 1.5169401      |\n",
            "| policy_loss        | -0.00023979112 |\n",
            "| serial_timesteps   | 2048           |\n",
            "| time_elapsed       | 2.08           |\n",
            "| total_timesteps    | 2048           |\n",
            "| value_loss         | 67.322105      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0002273258  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0717       |\n",
            "| fps                | 973           |\n",
            "| n_updates          | 17            |\n",
            "| policy_entropy     | 1.5181677     |\n",
            "| policy_loss        | 0.00019336562 |\n",
            "| serial_timesteps   | 2176          |\n",
            "| time_elapsed       | 2.2           |\n",
            "| total_timesteps    | 2176          |\n",
            "| value_loss         | 116.39298     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 5.3442338e-05  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | -0.00119       |\n",
            "| fps                | 923            |\n",
            "| n_updates          | 18             |\n",
            "| policy_entropy     | 1.5306922      |\n",
            "| policy_loss        | -0.00034828437 |\n",
            "| serial_timesteps   | 2304           |\n",
            "| time_elapsed       | 2.33           |\n",
            "| total_timesteps    | 2304           |\n",
            "| value_loss         | 159.67172      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00018073936 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0411       |\n",
            "| fps                | 1111          |\n",
            "| n_updates          | 19            |\n",
            "| policy_entropy     | 1.4951373     |\n",
            "| policy_loss        | -0.001460374  |\n",
            "| serial_timesteps   | 2432          |\n",
            "| time_elapsed       | 2.47          |\n",
            "| total_timesteps    | 2432          |\n",
            "| value_loss         | 63.86215      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00057386886 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00395      |\n",
            "| fps                | 1112          |\n",
            "| n_updates          | 20            |\n",
            "| policy_entropy     | 1.4960765     |\n",
            "| policy_loss        | -0.0036255843 |\n",
            "| serial_timesteps   | 2560          |\n",
            "| time_elapsed       | 2.59          |\n",
            "| total_timesteps    | 2560          |\n",
            "| value_loss         | 41.874786     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0009334035  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0435       |\n",
            "| fps                | 991           |\n",
            "| n_updates          | 21            |\n",
            "| policy_entropy     | 1.5271288     |\n",
            "| policy_loss        | -0.0018282268 |\n",
            "| serial_timesteps   | 2688          |\n",
            "| time_elapsed       | 2.71          |\n",
            "| total_timesteps    | 2688          |\n",
            "| value_loss         | 68.470726     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0002757328  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00356      |\n",
            "| fps                | 1088          |\n",
            "| n_updates          | 22            |\n",
            "| policy_entropy     | 1.5399957     |\n",
            "| policy_loss        | 0.00018526381 |\n",
            "| serial_timesteps   | 2816          |\n",
            "| time_elapsed       | 2.84          |\n",
            "| total_timesteps    | 2816          |\n",
            "| value_loss         | 37.86446      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00033372763 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00193       |\n",
            "| fps                | 1013          |\n",
            "| n_updates          | 23            |\n",
            "| policy_entropy     | 1.5424651     |\n",
            "| policy_loss        | -0.0017829313 |\n",
            "| serial_timesteps   | 2944          |\n",
            "| time_elapsed       | 2.96          |\n",
            "| total_timesteps    | 2944          |\n",
            "| value_loss         | 24.703337     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00027459685 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00968      |\n",
            "| fps                | 1003          |\n",
            "| n_updates          | 24            |\n",
            "| policy_entropy     | 1.5238994     |\n",
            "| policy_loss        | 0.0040225     |\n",
            "| serial_timesteps   | 3072          |\n",
            "| time_elapsed       | 3.08          |\n",
            "| total_timesteps    | 3072          |\n",
            "| value_loss         | 1.7278934     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00026000134 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00212      |\n",
            "| fps                | 997           |\n",
            "| n_updates          | 25            |\n",
            "| policy_entropy     | 1.5248102     |\n",
            "| policy_loss        | -0.0015111546 |\n",
            "| serial_timesteps   | 3200          |\n",
            "| time_elapsed       | 3.21          |\n",
            "| total_timesteps    | 3200          |\n",
            "| value_loss         | 2.22363       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 5.693012e-05 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | 0.0118       |\n",
            "| fps                | 1012         |\n",
            "| n_updates          | 26           |\n",
            "| policy_entropy     | 1.5379632    |\n",
            "| policy_loss        | 0.0018451947 |\n",
            "| serial_timesteps   | 3328         |\n",
            "| time_elapsed       | 3.34         |\n",
            "| total_timesteps    | 3328         |\n",
            "| value_loss         | 5.695645     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00020388386 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0245       |\n",
            "| fps                | 1027          |\n",
            "| n_updates          | 27            |\n",
            "| policy_entropy     | 1.5484213     |\n",
            "| policy_loss        | -0.0041436404 |\n",
            "| serial_timesteps   | 3456          |\n",
            "| time_elapsed       | 3.47          |\n",
            "| total_timesteps    | 3456          |\n",
            "| value_loss         | 101.033424    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0008469466  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0254        |\n",
            "| fps                | 969           |\n",
            "| n_updates          | 28            |\n",
            "| policy_entropy     | 1.5253854     |\n",
            "| policy_loss        | -0.0068224017 |\n",
            "| serial_timesteps   | 3584          |\n",
            "| time_elapsed       | 3.6           |\n",
            "| total_timesteps    | 3584          |\n",
            "| value_loss         | 6.201889      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00017809425 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0278       |\n",
            "| fps                | 1036          |\n",
            "| n_updates          | 29            |\n",
            "| policy_entropy     | 1.5090858     |\n",
            "| policy_loss        | 0.0010683037  |\n",
            "| serial_timesteps   | 3712          |\n",
            "| time_elapsed       | 3.74          |\n",
            "| total_timesteps    | 3712          |\n",
            "| value_loss         | 27.74207      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00012814181 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00233      |\n",
            "| fps                | 981           |\n",
            "| n_updates          | 30            |\n",
            "| policy_entropy     | 1.5118783     |\n",
            "| policy_loss        | -0.0007753479 |\n",
            "| serial_timesteps   | 3840          |\n",
            "| time_elapsed       | 3.87          |\n",
            "| total_timesteps    | 3840          |\n",
            "| value_loss         | 71.6088       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0009309332 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.00572     |\n",
            "| fps                | 914          |\n",
            "| n_updates          | 31           |\n",
            "| policy_entropy     | 1.5078129    |\n",
            "| policy_loss        | -0.004539271 |\n",
            "| serial_timesteps   | 3968         |\n",
            "| time_elapsed       | 4            |\n",
            "| total_timesteps    | 3968         |\n",
            "| value_loss         | 78.18377     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00083533034 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.000839      |\n",
            "| fps                | 1016          |\n",
            "| n_updates          | 32            |\n",
            "| policy_entropy     | 1.4958926     |\n",
            "| policy_loss        | -0.0025695453 |\n",
            "| serial_timesteps   | 4096          |\n",
            "| time_elapsed       | 4.14          |\n",
            "| total_timesteps    | 4096          |\n",
            "| value_loss         | 71.10477      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0003479296  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00509      |\n",
            "| fps                | 1034          |\n",
            "| n_updates          | 33            |\n",
            "| policy_entropy     | 1.4811075     |\n",
            "| policy_loss        | 0.00046161364 |\n",
            "| serial_timesteps   | 4224          |\n",
            "| time_elapsed       | 4.27          |\n",
            "| total_timesteps    | 4224          |\n",
            "| value_loss         | 38.976353     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00070295    |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 5.11e-05      |\n",
            "| fps                | 1074          |\n",
            "| n_updates          | 34            |\n",
            "| policy_entropy     | 1.4883419     |\n",
            "| policy_loss        | -0.0026192868 |\n",
            "| serial_timesteps   | 4352          |\n",
            "| time_elapsed       | 4.4           |\n",
            "| total_timesteps    | 4352          |\n",
            "| value_loss         | 34.424362     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00071926735  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | 0.00775        |\n",
            "| fps                | 1073           |\n",
            "| n_updates          | 35             |\n",
            "| policy_entropy     | 1.5173678      |\n",
            "| policy_loss        | -0.00033362792 |\n",
            "| serial_timesteps   | 4480           |\n",
            "| time_elapsed       | 4.52           |\n",
            "| total_timesteps    | 4480           |\n",
            "| value_loss         | 21.992783      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 2.299075e-05 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.011       |\n",
            "| fps                | 986          |\n",
            "| n_updates          | 36           |\n",
            "| policy_entropy     | 1.5309705    |\n",
            "| policy_loss        | 8.167804e-05 |\n",
            "| serial_timesteps   | 4608         |\n",
            "| time_elapsed       | 4.64         |\n",
            "| total_timesteps    | 4608         |\n",
            "| value_loss         | 5.1353745    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00017437973 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.069         |\n",
            "| fps                | 998           |\n",
            "| n_updates          | 37            |\n",
            "| policy_entropy     | 1.5212137     |\n",
            "| policy_loss        | 0.0013529677  |\n",
            "| serial_timesteps   | 4736          |\n",
            "| time_elapsed       | 4.77          |\n",
            "| total_timesteps    | 4736          |\n",
            "| value_loss         | 6.7876115     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00014553053 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0608        |\n",
            "| fps                | 1104          |\n",
            "| n_updates          | 38            |\n",
            "| policy_entropy     | 1.5177442     |\n",
            "| policy_loss        | -0.002428628  |\n",
            "| serial_timesteps   | 4864          |\n",
            "| time_elapsed       | 4.9           |\n",
            "| total_timesteps    | 4864          |\n",
            "| value_loss         | 3.3738923     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.00017553178  |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | 0.0244         |\n",
            "| fps                | 1045           |\n",
            "| n_updates          | 39             |\n",
            "| policy_entropy     | 1.510125       |\n",
            "| policy_loss        | -0.00046369876 |\n",
            "| serial_timesteps   | 4992           |\n",
            "| time_elapsed       | 5.02           |\n",
            "| total_timesteps    | 4992           |\n",
            "| value_loss         | 6.147025       |\n",
            "---------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR5rdvTK2hGN",
        "outputId": "c127912f-e1d8-4472-8375-f8dc57c0c35b"
      },
      "source": [
        "obs = env.reset()\n",
        "n_steps = 100\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", action)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render(mode='console')\n",
        "  if done:\n",
        "    # Note that the VecEnv resets automatically\n",
        "    # when a done signal is encountered\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 2\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 3\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 4\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 5\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 6\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 7\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 8\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 9\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 10\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 11\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 12\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 13\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 14\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 15\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 16\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 17\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 18\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 19\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 20\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 21\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 22\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 23\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 24\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 25\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 26\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 27\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 28\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 29\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 30\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 31\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 32\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 33\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 34\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 35\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 36\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 37\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 38\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 39\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 40\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 41\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 42\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 43\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 44\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 45\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 46\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 47\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 48\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 49\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 50\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 51\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 52\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 53\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 54\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 55\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 56\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 57\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 58\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 59\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 60\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 61\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 62\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 63\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 64\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 65\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 66\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 67\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 68\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 69\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 70\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 71\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 72\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 73\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 74\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 75\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 76\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 77\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 78\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 79\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 80\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 81\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 82\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 83\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 84\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 85\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 86\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 87\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 88\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 89\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 90\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 91\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 92\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 93\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 94\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 95\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 96\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 97\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 98\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 99\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 100\n",
            "Action:  [2]\n",
            "obs= [[ 29.  23. -14.  -8.]] reward= [-0.42] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUE6Uos6sRe"
      },
      "source": [
        "model.save(\"ppo2_single_agent\")"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUSe4kzMfv2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}