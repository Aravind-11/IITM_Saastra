{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Single agent with obstacle following.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aravind-11/IITM_Saastra/blob/main/Single_agent_with_obstacle_following.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uOS5--D04D3"
      },
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "class Football:  # The class encapsulating the environment\n",
        "    '''\n",
        "    Actions [0 : Stand, 1 : Up, 2 : Right, 3 : Down, 4 : Left]\n",
        "    These are the representing no.s for the mentioned actions\n",
        "    '''\n",
        "\n",
        "    def __init__(self, length=30, width=30, goalPositions=[29, 15]):\n",
        "        \n",
        "        # The player start at random locations\n",
        "        \n",
        "        self.pA=[np.random.randint(length), np.random.randint(length)] \n",
        "        self.pO=[6,8]\n",
        "            \n",
        "        \n",
        "        self.h = length   # Length of the Football Pitch    \n",
        "        self.w = width    # Width of the Football Pitch\n",
        "        \n",
        "        self.goalPositions = np.array(goalPositions)   # This means that the middle 4 positions at the right and left are the goals\n",
        "        \n",
        "     \n",
        "        \n",
        "        self.reward = 0                            # Initially the reward is 0\n",
        "        \n",
        "        self.observation=np.random.rand(6,)\n",
        "        self.done = bool(0)                          # This stores whether the game needs to be restart with new position (in the case of a goal)\n",
        "\n",
        "    def reset(self):\n",
        "        self.done = bool(0)\n",
        "        self.reward = 0\n",
        "        \n",
        "        self.pA = np.array([np.random.randint(self.h), np.random.randint(self.h)])\n",
        "        self.pO=[6,8]\n",
        "        \n",
        "        return np.array((*self.pA,(15-self.pA[0]),(15-self.pA[1]),*self.pO)).astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        if self.done == bool(1):\n",
        "          self.reset()\n",
        "        self.move(first, action)                   # We chose the first player at random\n",
        "        if self.done == bool(1):\n",
        "          return self.observation, self.reward, self.done\n",
        "        if not done:\n",
        "            self.current_player_num = (self.current_player_num + 1) % 2   \n",
        "        return self.observation,self.reward, self.done\n",
        "\n",
        "    def move(self, player, action):\n",
        "        opponent = 1 - player\n",
        "        \n",
        "        newPosition = self.pA + self.actionToMove(action)\n",
        "        \n",
        "        if self.ballOwner is player and self.isInGoal(*newPosition) >= 0:\n",
        "            self.done = bool(1)\n",
        "            return 1 - self.isInGoal(*newPosition)\n",
        "        # If it's in the board\n",
        "        elif self.isInBoard(*newPosition):\n",
        "            self.positions[player] = newPosition\n",
        "        if(self.ballOwner!=0):\n",
        "          self.reward=-1\n",
        "        return -1\n",
        "\n",
        "    def actionToMove(self, action):\n",
        "        switcher = {\n",
        "            0: [0, 0],\n",
        "            1: [0, 1],\n",
        "            2: [1, 0],\n",
        "            3: [0, -1],\n",
        "            4: [-1, 0],\n",
        "        }\n",
        "        return switcher.get(action)\n",
        "\n",
        "    def isInGoal(self, x, y):\n",
        "        g1, g2 = self.goalPositions\n",
        "        if (g1 <= y <= g2):\n",
        "            if x == 0:\n",
        "                self.done = bool(1)\n",
        "                self.reward = -20 # if the ball reaches the right goal post, then the rewards shall be -1\n",
        "                return 1 \n",
        "            elif x == (self.w-1):\n",
        "                self.done = bool(1)\n",
        "                self.reward = 20 # if the ball reaches the right goal post, then the rewards shall be 1\n",
        "                return 0\n",
        "        return -1\n",
        "\n",
        "    def isInBoard(self, x, y):\n",
        "        if(x<0 or x>29):\n",
        "          return 0\n",
        "        if(y<0 or y>29):\n",
        "          return 0 \n",
        "        return 1\n",
        "        \n",
        "\n",
        "    #def choosePlayer(self):\n",
        "    #    return np.random.randint(0, 2)\n",
        "    def render(self,mode=\"human\"):\n",
        "        \n",
        "\n",
        "        board = ''\n",
        "        for y in range(self.h)[::-1]:\n",
        "            for x in range(self.w):\n",
        "                if ([x, y] == self.pA).all():\n",
        "                    board += 'A' \n",
        "                elif([x,y]==self.pO):\n",
        "                  board+='O'\n",
        "                else:\n",
        "                    board += '-'\n",
        "            board += '\\n'\n",
        "\n",
        "        print(board)\n",
        "\n",
        "class modf_football(Football,gym.Env):\n",
        "  def __init__(self, length=30, width=30, goalPositions=[29, 15]):\n",
        "    super().__init__()\n",
        "    self.observation_space=gym.spaces.Box(low=-30, high=30,\n",
        "                                        shape=(6,), dtype=np.float32)\n",
        "    self.reward=0\n",
        "    self.action_space=gym.spaces.Discrete(5)\n",
        "    self.name='Football'\n",
        "    self.current_player_num=0\n",
        "    self.observation=np.random.rand(6,)\n",
        "    self.pA = np.array([np.random.randint(self.h), np.random.randint(self.h)])\n",
        "  #modifying the step and move function to get the updated reward system\n",
        "  def step(self, action):\n",
        "        #print('action',action)\n",
        "        if self.done == bool(1):\n",
        "          self.reset()\n",
        "        \n",
        "        self.move(action)                   # We chose the first player at random\n",
        "        if self.done == bool(1):\n",
        "          return self.observation, self.reward, self.done,{}\n",
        "        if not self.done:\n",
        "            self.current_player_num = 0\n",
        "        return self.observation,self.reward, self.done,{}\n",
        "  \n",
        "  def move(self, action):\n",
        "        \n",
        "        newPosition = self.pA + self.actionToMove(action)\n",
        "\n",
        "        if (self.pO[0]>self.pA[0]):\n",
        "          self.pO[0]-=1\n",
        "        elif (self.pO[0]<self.pA[0]):\n",
        "          self.pO[0]+=1\n",
        "        if (self.pO[1]>self.pA[1]):\n",
        "          self.pO[1]-=1\n",
        "        elif (self.pO[1]<self.pA[1]):\n",
        "          self.pO[1]+=1\n",
        "        \n",
        "        self.pO[0]=max(self.pO[0],0)\n",
        "        self.pO[0]=min(self.pO[0],29)\n",
        "        self.pO[1]=max(self.pO[1],0)\n",
        "        self.pO[1]=min(self.pO[1],29)\n",
        "\n",
        "        if self.isInGoal(*newPosition) >= 0:\n",
        "            self.done = bool(1)\n",
        "            return 1 - self.isInGoal(*newPosition)\n",
        "        # If it's in the board\n",
        "        elif self.isInBoard(*newPosition):\n",
        "            self.reward = -0.1 * ((((abs(newPosition[0]-self.goalPositions[0]))+(abs(newPosition[1]-self.goalPositions[1]))))) +0.01*(abs(newPosition[0]-self.pO[0])+abs(newPosition[1]-self.pO[1]))\n",
        "            self.pA = newPosition\n",
        "        \n",
        "        self.observation=np.array((*self.pA,(15-self.pA[0]),(15-self.pA[1]),*self.pO)).astype(np.float32)\n",
        "        return -1\n",
        "  def seed():\n",
        "      return 0 \n",
        "  def metadata(x):\n",
        "      return 0 \n",
        "  def legal_actions(self):\n",
        "    return gym.spaces.Discrete(5)\n",
        "  def close(self):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAVZUc4H0_uK"
      },
      "source": [
        "env=modf_football(Football,gym.Env)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XDWqICr1GhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f77b47-f6e5-4ad6-94f3-2cef87bd328a"
      },
      "source": [
        "print(\"Observation space:\", env.observation_space)\n",
        "print(\"Shape:\", env.observation_space.shape)\n",
        "# Discrete(2) means that there is two discrete actions\n",
        "print(\"Action space:\", env.action_space)\n",
        "\n",
        "# The reset method is called at the beginning of an episode\n",
        "obs = env.reset()\n",
        "# Sample a random action\n",
        "action = env.action_space.sample()\n",
        "print(\"Sampled action:\", action)\n",
        "obs, reward, done, info = env.step(action)\n",
        "# Note the obs is a numpy array\n",
        "# info is an empty dict for now but can contain any debugging info\n",
        "# reward is a scalar\n",
        "print(obs, reward, done, info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation space: Box(-30.0, 30.0, (6,), float32)\n",
            "Shape: (6,)\n",
            "Action space: Discrete(5)\n",
            "Sampled action: 2\n",
            "[ 7.  5.  8. 10.  6.  7.] -3.1700000000000004 False {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twZOQXF60_KR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9131443-4d57-4f76-f877-6e2ea04a7448"
      },
      "source": [
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x\n",
        "!pip install stable-baselines[mpi]==2.10.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting stable-baselines[mpi]==2.10.0\n",
            "  Downloading stable_baselines-2.10.0-py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 16.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.19.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (4.1.2.30)\n",
            "Requirement already satisfied: cloudpickle>=0.5.5 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.1.5)\n",
            "Requirement already satisfied: gym[atari,classic_control]>=0.11 in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (0.17.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from stable-baselines[mpi]==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: mpi4py in /tensorflow-1.15.2/python3.7 (from stable-baselines[mpi]==2.10.0) (3.0.3)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (7.1.2)\n",
            "Requirement already satisfied: atari-py~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.2.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari,classic_control]>=0.11->stable-baselines[mpi]==2.10.0) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->stable-baselines[mpi]==2.10.0) (2.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->stable-baselines[mpi]==2.10.0) (2018.9)\n",
            "Installing collected packages: stable-baselines\n",
            "  Attempting uninstall: stable-baselines\n",
            "    Found existing installation: stable-baselines 2.2.1\n",
            "    Uninstalling stable-baselines-2.2.1:\n",
            "      Successfully uninstalled stable-baselines-2.2.1\n",
            "Successfully installed stable-baselines-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCKuQTfQ1IRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac0ad93-71b2-413f-fe36-d7af84c7333e"
      },
      "source": [
        "from stable_baselines.common.env_checker import check_env"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xnffJrv1K03"
      },
      "source": [
        "check_env(env, warn=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHUcyqRd1K2Q"
      },
      "source": [
        "from stable_baselines import DQN, PPO2, A2C, ACKTR\n",
        "from stable_baselines.common.cmd_util import make_vec_env\n",
        "\n",
        "# Instantiate the env\n",
        "#env = GoLeftEnv(grid_size=10)\n",
        "# wrap it\n",
        "env = make_vec_env(lambda: env, n_envs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j1rooua2biy",
        "outputId": "f273cdaa-1ee4-4a94-980f-1f7daf1b47e2"
      },
      "source": [
        "\n",
        "# Train the agent\n",
        "model = PPO2('MlpPolicy', env, verbose=1).learn(5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------\n",
            "| approxkl           | 0.00018498908 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00105      |\n",
            "| fps                | 372           |\n",
            "| n_updates          | 1             |\n",
            "| policy_entropy     | 1.6092254     |\n",
            "| policy_loss        | -0.0017238527 |\n",
            "| serial_timesteps   | 128           |\n",
            "| time_elapsed       | 1.67e-05      |\n",
            "| total_timesteps    | 128           |\n",
            "| value_loss         | 1350.0603     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| approxkl           | 0.0001224053   |\n",
            "| clipfrac           | 0.0            |\n",
            "| explained_variance | 0.0185         |\n",
            "| fps                | 921            |\n",
            "| n_updates          | 2              |\n",
            "| policy_entropy     | 1.6085753      |\n",
            "| policy_loss        | -0.00037437375 |\n",
            "| serial_timesteps   | 256            |\n",
            "| time_elapsed       | 0.346          |\n",
            "| total_timesteps    | 256            |\n",
            "| value_loss         | 1200.3132      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00019433026 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0282        |\n",
            "| fps                | 959           |\n",
            "| n_updates          | 3             |\n",
            "| policy_entropy     | 1.6077085     |\n",
            "| policy_loss        | 0.00011940149 |\n",
            "| serial_timesteps   | 384           |\n",
            "| time_elapsed       | 0.487         |\n",
            "| total_timesteps    | 384           |\n",
            "| value_loss         | 808.17334     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00011157227 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00561       |\n",
            "| fps                | 1076          |\n",
            "| n_updates          | 4             |\n",
            "| policy_entropy     | 1.6085942     |\n",
            "| policy_loss        | -0.0018325187 |\n",
            "| serial_timesteps   | 512           |\n",
            "| time_elapsed       | 0.622         |\n",
            "| total_timesteps    | 512           |\n",
            "| value_loss         | 320.67084     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00018326499 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0206        |\n",
            "| fps                | 1081          |\n",
            "| n_updates          | 5             |\n",
            "| policy_entropy     | 1.6092485     |\n",
            "| policy_loss        | 0.0009933548  |\n",
            "| serial_timesteps   | 640           |\n",
            "| time_elapsed       | 0.743         |\n",
            "| total_timesteps    | 640           |\n",
            "| value_loss         | 349.57034     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00029539794 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00969      |\n",
            "| fps                | 1105          |\n",
            "| n_updates          | 6             |\n",
            "| policy_entropy     | 1.608602      |\n",
            "| policy_loss        | -0.0020927088 |\n",
            "| serial_timesteps   | 768           |\n",
            "| time_elapsed       | 0.863         |\n",
            "| total_timesteps    | 768           |\n",
            "| value_loss         | 396.54147     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00024770098 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0272        |\n",
            "| fps                | 965           |\n",
            "| n_updates          | 7             |\n",
            "| policy_entropy     | 1.606996      |\n",
            "| policy_loss        | 0.0018420891  |\n",
            "| serial_timesteps   | 896           |\n",
            "| time_elapsed       | 0.98          |\n",
            "| total_timesteps    | 896           |\n",
            "| value_loss         | 95.57582      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0007610898  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00944       |\n",
            "| fps                | 1007          |\n",
            "| n_updates          | 8             |\n",
            "| policy_entropy     | 1.6081768     |\n",
            "| policy_loss        | -0.0055648964 |\n",
            "| serial_timesteps   | 1024          |\n",
            "| time_elapsed       | 1.11          |\n",
            "| total_timesteps    | 1024          |\n",
            "| value_loss         | 142.80708     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0008197817  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0292       |\n",
            "| fps                | 1113          |\n",
            "| n_updates          | 9             |\n",
            "| policy_entropy     | 1.605866      |\n",
            "| policy_loss        | -0.0017627603 |\n",
            "| serial_timesteps   | 1152          |\n",
            "| time_elapsed       | 1.24          |\n",
            "| total_timesteps    | 1152          |\n",
            "| value_loss         | 463.27295     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00043395645 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.018        |\n",
            "| fps                | 1070          |\n",
            "| n_updates          | 10            |\n",
            "| policy_entropy     | 1.6006181     |\n",
            "| policy_loss        | -0.0035148133 |\n",
            "| serial_timesteps   | 1280          |\n",
            "| time_elapsed       | 1.36          |\n",
            "| total_timesteps    | 1280          |\n",
            "| value_loss         | 388.95087     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00036725664 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0127        |\n",
            "| fps                | 998           |\n",
            "| n_updates          | 11            |\n",
            "| policy_entropy     | 1.5939945     |\n",
            "| policy_loss        | -0.0002896312 |\n",
            "| serial_timesteps   | 1408          |\n",
            "| time_elapsed       | 1.48          |\n",
            "| total_timesteps    | 1408          |\n",
            "| value_loss         | 66.62588      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0007915212  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0318        |\n",
            "| fps                | 1061          |\n",
            "| n_updates          | 12            |\n",
            "| policy_entropy     | 1.5916154     |\n",
            "| policy_loss        | -0.0040301243 |\n",
            "| serial_timesteps   | 1536          |\n",
            "| time_elapsed       | 1.61          |\n",
            "| total_timesteps    | 1536          |\n",
            "| value_loss         | 64.970955     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0005149314  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0158       |\n",
            "| fps                | 977           |\n",
            "| n_updates          | 13            |\n",
            "| policy_entropy     | 1.5904992     |\n",
            "| policy_loss        | -0.0019794137 |\n",
            "| serial_timesteps   | 1664          |\n",
            "| time_elapsed       | 1.73          |\n",
            "| total_timesteps    | 1664          |\n",
            "| value_loss         | 90.85076      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00017736008 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0497        |\n",
            "| fps                | 951           |\n",
            "| n_updates          | 14            |\n",
            "| policy_entropy     | 1.5970744     |\n",
            "| policy_loss        | -9.726576e-05 |\n",
            "| serial_timesteps   | 1792          |\n",
            "| time_elapsed       | 1.87          |\n",
            "| total_timesteps    | 1792          |\n",
            "| value_loss         | 360.1797      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00023149376 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00884      |\n",
            "| fps                | 1080          |\n",
            "| n_updates          | 15            |\n",
            "| policy_entropy     | 1.5927664     |\n",
            "| policy_loss        | -0.0036476986 |\n",
            "| serial_timesteps   | 1920          |\n",
            "| time_elapsed       | 2             |\n",
            "| total_timesteps    | 1920          |\n",
            "| value_loss         | 200.28123     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0005870707  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.039        |\n",
            "| fps                | 1084          |\n",
            "| n_updates          | 16            |\n",
            "| policy_entropy     | 1.5830956     |\n",
            "| policy_loss        | -0.0021452291 |\n",
            "| serial_timesteps   | 2048          |\n",
            "| time_elapsed       | 2.12          |\n",
            "| total_timesteps    | 2048          |\n",
            "| value_loss         | 223.94194     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00071696687 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00202       |\n",
            "| fps                | 982           |\n",
            "| n_updates          | 17            |\n",
            "| policy_entropy     | 1.5789728     |\n",
            "| policy_loss        | -0.0023530275 |\n",
            "| serial_timesteps   | 2176          |\n",
            "| time_elapsed       | 2.24          |\n",
            "| total_timesteps    | 2176          |\n",
            "| value_loss         | 34.008957     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00014248733 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.000882      |\n",
            "| fps                | 1019          |\n",
            "| n_updates          | 18            |\n",
            "| policy_entropy     | 1.5755799     |\n",
            "| policy_loss        | -0.0014437088 |\n",
            "| serial_timesteps   | 2304          |\n",
            "| time_elapsed       | 2.37          |\n",
            "| total_timesteps    | 2304          |\n",
            "| value_loss         | 11.471173     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00023507941 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0108       |\n",
            "| fps                | 862           |\n",
            "| n_updates          | 19            |\n",
            "| policy_entropy     | 1.5729824     |\n",
            "| policy_loss        | -0.0036603066 |\n",
            "| serial_timesteps   | 2432          |\n",
            "| time_elapsed       | 2.5           |\n",
            "| total_timesteps    | 2432          |\n",
            "| value_loss         | 35.31741      |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| approxkl           | 0.00103102  |\n",
            "| clipfrac           | 0.0         |\n",
            "| explained_variance | 0.00609     |\n",
            "| fps                | 1022        |\n",
            "| n_updates          | 20          |\n",
            "| policy_entropy     | 1.5627457   |\n",
            "| policy_loss        | -0.00533562 |\n",
            "| serial_timesteps   | 2560        |\n",
            "| time_elapsed       | 2.65        |\n",
            "| total_timesteps    | 2560        |\n",
            "| value_loss         | 7.891079    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00024471708 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00122      |\n",
            "| fps                | 1058          |\n",
            "| n_updates          | 21            |\n",
            "| policy_entropy     | 1.5543442     |\n",
            "| policy_loss        | 0.0019938103  |\n",
            "| serial_timesteps   | 2688          |\n",
            "| time_elapsed       | 2.78          |\n",
            "| total_timesteps    | 2688          |\n",
            "| value_loss         | 3.08943       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0006073075 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.003       |\n",
            "| fps                | 1019         |\n",
            "| n_updates          | 22           |\n",
            "| policy_entropy     | 1.5551602    |\n",
            "| policy_loss        | 0.0029341492 |\n",
            "| serial_timesteps   | 2816         |\n",
            "| time_elapsed       | 2.9          |\n",
            "| total_timesteps    | 2816         |\n",
            "| value_loss         | 45.034958    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00025618458 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0055        |\n",
            "| fps                | 1059          |\n",
            "| n_updates          | 23            |\n",
            "| policy_entropy     | 1.549         |\n",
            "| policy_loss        | -0.0027960497 |\n",
            "| serial_timesteps   | 2944          |\n",
            "| time_elapsed       | 3.03          |\n",
            "| total_timesteps    | 2944          |\n",
            "| value_loss         | 17.744692     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0003300644 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.00367     |\n",
            "| fps                | 1008         |\n",
            "| n_updates          | 24           |\n",
            "| policy_entropy     | 1.5545859    |\n",
            "| policy_loss        | 0.0024920541 |\n",
            "| serial_timesteps   | 3072         |\n",
            "| time_elapsed       | 3.16         |\n",
            "| total_timesteps    | 3072         |\n",
            "| value_loss         | 4.60311      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0011355447 |\n",
            "| clipfrac           | 0.00390625   |\n",
            "| explained_variance | -0.0136      |\n",
            "| fps                | 963          |\n",
            "| n_updates          | 25           |\n",
            "| policy_entropy     | 1.5453941    |\n",
            "| policy_loss        | -0.007407928 |\n",
            "| serial_timesteps   | 3200         |\n",
            "| time_elapsed       | 3.28         |\n",
            "| total_timesteps    | 3200         |\n",
            "| value_loss         | 2.9544191    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00019228105 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.0226       |\n",
            "| fps                | 1039          |\n",
            "| n_updates          | 26            |\n",
            "| policy_entropy     | 1.5364821     |\n",
            "| policy_loss        | 0.0023791594  |\n",
            "| serial_timesteps   | 3328          |\n",
            "| time_elapsed       | 3.42          |\n",
            "| total_timesteps    | 3328          |\n",
            "| value_loss         | 38.105038     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0011543354  |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.0036        |\n",
            "| fps                | 1012          |\n",
            "| n_updates          | 27            |\n",
            "| policy_entropy     | 1.5429941     |\n",
            "| policy_loss        | -0.0033927877 |\n",
            "| serial_timesteps   | 3456          |\n",
            "| time_elapsed       | 3.54          |\n",
            "| total_timesteps    | 3456          |\n",
            "| value_loss         | 1.50442       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0012496447 |\n",
            "| clipfrac           | 0.001953125  |\n",
            "| explained_variance | 0.00344      |\n",
            "| fps                | 1043         |\n",
            "| n_updates          | 28           |\n",
            "| policy_entropy     | 1.53751      |\n",
            "| policy_loss        | -0.00933498  |\n",
            "| serial_timesteps   | 3584         |\n",
            "| time_elapsed       | 3.67         |\n",
            "| total_timesteps    | 3584         |\n",
            "| value_loss         | 2.1550677    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.0009815885  |\n",
            "| clipfrac           | 0.013671875   |\n",
            "| explained_variance | 0.00126       |\n",
            "| fps                | 1008          |\n",
            "| n_updates          | 29            |\n",
            "| policy_entropy     | 1.53408       |\n",
            "| policy_loss        | -0.0075770123 |\n",
            "| serial_timesteps   | 3712          |\n",
            "| time_elapsed       | 3.79          |\n",
            "| total_timesteps    | 3712          |\n",
            "| value_loss         | 0.13893488    |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0039787167 |\n",
            "| clipfrac           | 0.0546875    |\n",
            "| explained_variance | -0.00629     |\n",
            "| fps                | 1095         |\n",
            "| n_updates          | 30           |\n",
            "| policy_entropy     | 1.5273448    |\n",
            "| policy_loss        | -0.016149605 |\n",
            "| serial_timesteps   | 3840         |\n",
            "| time_elapsed       | 3.92         |\n",
            "| total_timesteps    | 3840         |\n",
            "| value_loss         | 0.66590273   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.000753975  |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.00982     |\n",
            "| fps                | 1087         |\n",
            "| n_updates          | 31           |\n",
            "| policy_entropy     | 1.5108287    |\n",
            "| policy_loss        | -0.005689944 |\n",
            "| serial_timesteps   | 3968         |\n",
            "| time_elapsed       | 4.04         |\n",
            "| total_timesteps    | 3968         |\n",
            "| value_loss         | 0.47617006   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0025105502 |\n",
            "| clipfrac           | 0.015625     |\n",
            "| explained_variance | 0.000234     |\n",
            "| fps                | 1058         |\n",
            "| n_updates          | 32           |\n",
            "| policy_entropy     | 1.4867785    |\n",
            "| policy_loss        | -0.008107036 |\n",
            "| serial_timesteps   | 4096         |\n",
            "| time_elapsed       | 4.16         |\n",
            "| total_timesteps    | 4096         |\n",
            "| value_loss         | 0.6457468    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00028100185 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00572      |\n",
            "| fps                | 1109          |\n",
            "| n_updates          | 33            |\n",
            "| policy_entropy     | 1.4769322     |\n",
            "| policy_loss        | -0.0023983037 |\n",
            "| serial_timesteps   | 4224          |\n",
            "| time_elapsed       | 4.29          |\n",
            "| total_timesteps    | 4224          |\n",
            "| value_loss         | 0.25512114    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00081908976 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | -0.00131      |\n",
            "| fps                | 941           |\n",
            "| n_updates          | 34            |\n",
            "| policy_entropy     | 1.4643126     |\n",
            "| policy_loss        | -0.0025556812 |\n",
            "| serial_timesteps   | 4352          |\n",
            "| time_elapsed       | 4.41          |\n",
            "| total_timesteps    | 4352          |\n",
            "| value_loss         | 0.39445797    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| approxkl           | 0.00022717012 |\n",
            "| clipfrac           | 0.0           |\n",
            "| explained_variance | 0.00102       |\n",
            "| fps                | 1012          |\n",
            "| n_updates          | 35            |\n",
            "| policy_entropy     | 1.4508358     |\n",
            "| policy_loss        | -0.0035112714 |\n",
            "| serial_timesteps   | 4480          |\n",
            "| time_elapsed       | 4.54          |\n",
            "| total_timesteps    | 4480          |\n",
            "| value_loss         | 1.9749097     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0024694703 |\n",
            "| clipfrac           | 0.029296875  |\n",
            "| explained_variance | -0.00367     |\n",
            "| fps                | 1053         |\n",
            "| n_updates          | 36           |\n",
            "| policy_entropy     | 1.4680418    |\n",
            "| policy_loss        | -0.01507231  |\n",
            "| serial_timesteps   | 4608         |\n",
            "| time_elapsed       | 4.67         |\n",
            "| total_timesteps    | 4608         |\n",
            "| value_loss         | 0.9284898    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0005078014 |\n",
            "| clipfrac           | 0.0          |\n",
            "| explained_variance | -0.000212    |\n",
            "| fps                | 1078         |\n",
            "| n_updates          | 37           |\n",
            "| policy_entropy     | 1.4356122    |\n",
            "| policy_loss        | -0.003827519 |\n",
            "| serial_timesteps   | 4736         |\n",
            "| time_elapsed       | 4.8          |\n",
            "| total_timesteps    | 4736         |\n",
            "| value_loss         | 0.86982936   |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0039244713 |\n",
            "| clipfrac           | 0.037109375  |\n",
            "| explained_variance | -0.000857    |\n",
            "| fps                | 1083         |\n",
            "| n_updates          | 38           |\n",
            "| policy_entropy     | 1.3665347    |\n",
            "| policy_loss        | -0.017383011 |\n",
            "| serial_timesteps   | 4864         |\n",
            "| time_elapsed       | 4.92         |\n",
            "| total_timesteps    | 4864         |\n",
            "| value_loss         | 1.5302719    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| approxkl           | 0.0040720394 |\n",
            "| clipfrac           | 0.044921875  |\n",
            "| explained_variance | -0.00263     |\n",
            "| fps                | 907          |\n",
            "| n_updates          | 39           |\n",
            "| policy_entropy     | 1.3474013    |\n",
            "| policy_loss        | -0.017639518 |\n",
            "| serial_timesteps   | 4992         |\n",
            "| time_elapsed       | 5.04         |\n",
            "| total_timesteps    | 4992         |\n",
            "| value_loss         | 0.15218706   |\n",
            "-------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR5rdvTK2hGN",
        "outputId": "3552e1d2-0527-45af-fbdc-1602379f0a70"
      },
      "source": [
        "obs = env.reset()\n",
        "n_steps = 100\n",
        "for step in range(n_steps):\n",
        "  action, _ = model.predict(obs, deterministic=True)\n",
        "  print(\"Step {}\".format(step + 1))\n",
        "  print(\"Action: \", action)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  print('obs=', obs, 'reward=', reward, 'done=', done)\n",
        "  env.render(mode='console')\n",
        "  if done:\n",
        "    # Note that the VecEnv resets automatically\n",
        "    # when a done signal is encountered\n",
        "    print(\"Goal reached!\", \"reward=\", reward)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1\n",
            "Action:  [2]\n",
            "obs= [[ 4. 16. 11. -1.  5.  9.]] reward= [-2.52] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----A-------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----O------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 2\n",
            "Action:  [2]\n",
            "obs= [[ 5. 16. 10. -1.  4. 10.]] reward= [-2.43] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----A------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----O-------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 3\n",
            "Action:  [2]\n",
            "obs= [[ 6. 16.  9. -1.  5. 11.]] reward= [-2.34] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------A-----------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----O------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 4\n",
            "Action:  [2]\n",
            "obs= [[ 7. 16.  8. -1.  6. 12.]] reward= [-2.25] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-------A----------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------O-----------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 5\n",
            "Action:  [2]\n",
            "obs= [[ 8. 16.  7. -1.  7. 13.]] reward= [-2.16] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------A---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-------O----------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 6\n",
            "Action:  [2]\n",
            "obs= [[ 9. 16.  6. -1.  8. 14.]] reward= [-2.07] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "---------A--------------------\n",
            "------------------------------\n",
            "--------O---------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 7\n",
            "Action:  [2]\n",
            "obs= [[10. 16.  5. -1.  9. 15.]] reward= [-1.98] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----------A-------------------\n",
            "---------O--------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 8\n",
            "Action:  [2]\n",
            "obs= [[11. 16.  4. -1. 10. 16.]] reward= [-1.89] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----------OA------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 9\n",
            "Action:  [2]\n",
            "obs= [[12. 16.  3. -1. 11. 16.]] reward= [-1.79] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------OA-----------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 10\n",
            "Action:  [2]\n",
            "obs= [[13. 16.  2. -1. 12. 16.]] reward= [-1.69] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------OA----------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 11\n",
            "Action:  [2]\n",
            "obs= [[14. 16.  1. -1. 13. 16.]] reward= [-1.59] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-------------OA---------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 12\n",
            "Action:  [2]\n",
            "obs= [[15. 16.  0. -1. 14. 16.]] reward= [-1.49] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------------OA--------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 13\n",
            "Action:  [2]\n",
            "obs= [[16. 16. -1. -1. 15. 16.]] reward= [-1.39] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "---------------OA-------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 14\n",
            "Action:  [2]\n",
            "obs= [[17. 16. -2. -1. 16. 16.]] reward= [-1.29] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----------------OA------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 15\n",
            "Action:  [2]\n",
            "obs= [[18. 16. -3. -1. 17. 16.]] reward= [-1.19] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------OA-----------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 16\n",
            "Action:  [2]\n",
            "obs= [[19. 16. -4. -1. 18. 16.]] reward= [-1.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------OA----------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 17\n",
            "Action:  [2]\n",
            "obs= [[20. 16. -5. -1. 19. 16.]] reward= [-0.99] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-------------------OA---------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 18\n",
            "Action:  [2]\n",
            "obs= [[21. 16. -6. -1. 20. 16.]] reward= [-0.89] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------------------OA--------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 19\n",
            "Action:  [2]\n",
            "obs= [[22. 16. -7. -1. 21. 16.]] reward= [-0.79] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "---------------------OA-------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 20\n",
            "Action:  [2]\n",
            "obs= [[23. 16. -8. -1. 22. 16.]] reward= [-0.69] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----------------------OA------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 21\n",
            "Action:  [2]\n",
            "obs= [[24. 16. -9. -1. 23. 16.]] reward= [-0.59] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------OA-----\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 22\n",
            "Action:  [2]\n",
            "obs= [[ 25.  16. -10.  -1.  24.  16.]] reward= [-0.49] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------OA----\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 23\n",
            "Action:  [2]\n",
            "obs= [[ 26.  16. -11.  -1.  25.  16.]] reward= [-0.39] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-------------------------OA---\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 24\n",
            "Action:  [2]\n",
            "obs= [[ 27.  16. -12.  -1.  26.  16.]] reward= [-0.29] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "--------------------------OA--\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 25\n",
            "Action:  [2]\n",
            "obs= [[ 28.  16. -13.  -1.  27.  16.]] reward= [-0.19] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "---------------------------OA-\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 26\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  28.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "----------------------------OA\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 27\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 28\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 29\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 30\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 31\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 32\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 33\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 34\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 35\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 36\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 37\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 38\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 39\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 40\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 41\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 42\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 43\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 44\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 45\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 46\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 47\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 48\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 49\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 50\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 51\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 52\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 53\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 54\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 55\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 56\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 57\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 58\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 59\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 60\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 61\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 62\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 63\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 64\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 65\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 66\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 67\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 68\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 69\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 70\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 71\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 72\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 73\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 74\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 75\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 76\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 77\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 78\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 79\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 80\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 81\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 82\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 83\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 84\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 85\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 86\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 87\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 88\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 89\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 90\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 91\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 92\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 93\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 94\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 95\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 96\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 97\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 98\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 99\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n",
            "Step 100\n",
            "Action:  [2]\n",
            "obs= [[ 29.  16. -14.  -1.  29.  16.]] reward= [-0.09] done= [False]\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "-----------------------------A\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydUE6Uos6sRe"
      },
      "source": [
        "model.save(\"ppo2_single_agent_moving_obstacle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUSe4kzMfv2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}